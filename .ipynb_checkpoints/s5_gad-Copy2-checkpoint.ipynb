{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c004dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# 2022-12-02 17:02:26.857 [DEBUG] [attrs.py:77] Creating converter from 3 to 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 数量： 21\n",
      "celltype names: ['Macrophages', 'T cell lineage', 'Unknown', 'B cell lineage', 'Innate lymphoid cell NK', 'AT2', 'Monocytes', 'Multiciliated lineage', 'Dendritic cells', 'EC capillary', 'Mast cells', 'Fibroblasts', 'Secretory', 'EC venous', 'Lymphatic EC mature', 'AT1', 'Basal', 'EC arterial', 'Myofibroblasts', 'None', 'Submucosal Secretory']\n",
      "-----------------------  ----\n",
      "Macrophages              6941\n",
      "T cell lineage            749\n",
      "Unknown                   618\n",
      "B cell lineage            374\n",
      "Innate lymphoid cell NK   327\n",
      "AT2                       294\n",
      "Monocytes                 228\n",
      "Multiciliated lineage     194\n",
      "Dendritic cells           177\n",
      "EC capillary              138\n",
      "Mast cells                100\n",
      "Fibroblasts                93\n",
      "Secretory                  86\n",
      "EC venous                  74\n",
      "Lymphatic EC mature        68\n",
      "AT1                        27\n",
      "Basal                      26\n",
      "EC arterial                20\n",
      "Myofibroblasts             17\n",
      "None                        6\n",
      "Submucosal Secretory        1\n",
      "-----------------------  ----\n",
      "各marker list所包含的gene数：\n",
      "  Markers1    Markers2    Markers3    Markers4\n",
      "----------  ----------  ----------  ----------\n",
      "       126          78         145          84\n",
      "total marker genes:  380\n",
      "highly_genes num:  2000\n",
      "After highly genes dropped duplicate:  1935\n",
      "Total gene num: 2286\n",
      "cell num: 10558, gene num: 2286\n",
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from community import community_louvain\n",
    "from torch_geometric.utils import k_hop_subgraph,to_networkx,from_networkx\n",
    "import matplotlib\n",
    "\n",
    "import utils\n",
    "import plots\n",
    "from model_AE import reduction_AE\n",
    "from model_GAT import Encoder,SenGAE,train_GAT\n",
    "from model_Sencell import Sencell\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Main program for sencells')\n",
    "\n",
    "parser.add_argument('--output_dir', type=str, default='./outputs', help='')\n",
    "parser.add_argument('--exp_name', type=str, default='', help='')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.exp_name='s5'\n",
    "\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s.%(msecs)03d [%(levelname)s] [%(filename)s:%(lineno)d] %(message)s',\n",
    "                    datefmt='# %Y-%m-%d %H:%M:%S')\n",
    "\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Part 1: load and process data\n",
    "# cell_cluster_arr在画umap的时候用\n",
    "adata,cluster_cell_ls,cell_cluster_arr,celltype_names=utils.load_data()\n",
    "# plots.umapPlot(adata.obsm['X_umap'],clusters=cell_cluster_arr,labels=celltype_names)\n",
    "\n",
    "new_data,markers_index,\\\n",
    "sen_gene_ls,nonsen_gene_ls,gene_names=utils.process_data(adata,cluster_cell_ls,cell_cluster_arr)\n",
    "\n",
    "print(f'cell num: {new_data.shape[0]}, gene num: {new_data.shape[1]}')\n",
    "\n",
    "gene_cell=new_data.X.toarray().T\n",
    "cell_gene=gene_cell.T\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device: ',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b279ff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent process 267698.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10558/10558 [00:00<00:00, 36528.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for all subprocesses done...\n",
      "All subprocesses done.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_simi(i,my_dict):\n",
    "    for j in range(i+1,cell_gene.shape[0]):\n",
    "        u1=cell_gene[i]\n",
    "        u2=cell_gene[j]\n",
    "        # u1,u2必须是numpy.array，not tensor\n",
    "        nz_u1 = u1.nonzero()[0]\n",
    "        nz_u2 = u2.nonzero()[0]\n",
    "        nz_inter = set(nz_u1) & set(nz_u2)\n",
    "        nz_union = set(nz_u1) | set(nz_u2)\n",
    "        if len(nz_inter) == 0:\n",
    "            simi_score = 1 / (len(nz_union) + len(u1))\n",
    "        elif len(nz_inter) == len(nz_union):\n",
    "            simi_score = (len(nz_union) + len(u1) - 1) / (len(nz_union) + len(u1))\n",
    "        else:\n",
    "            simi_score = len(nz_inter) / len(nz_union)\n",
    "        my_dict[(i,j)]=simi_score\n",
    "\n",
    "\n",
    "def eucliDistance(v1,v2):\n",
    "    # 计算欧氏距离\n",
    "    return F.pairwise_distance(v1.view(1,-1),v2.view(1,-1),p=2)\n",
    "\n",
    "def loss_exp(v1,v2):\n",
    "    return torch.exp(-0.1*eucliDistance(v1,v2))\n",
    "\n",
    "sim1_ls=[]\n",
    "cell_gene=gene_cell.T    \n",
    "results_matrix=np.zeros((cell_gene.shape[0],cell_gene.shape[0])) \n",
    "\n",
    "\n",
    "from multiprocessing import Pool,Manager\n",
    "import os, time, random\n",
    "\n",
    "\n",
    "print('Parent process %s.' % os.getpid())\n",
    "p = Pool()\n",
    "manager = Manager()\n",
    "my_dict = manager.dict()\n",
    "for i in tqdm(range(cell_gene.shape[0])):\n",
    "    p.apply_async(get_simi, args=(i,my_dict,))\n",
    "\n",
    "print('Waiting for all subprocesses done...')\n",
    "p.close()\n",
    "p.join()\n",
    "print('All subprocesses done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0f2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17:02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270023c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "789726ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 427/10558 [02:37<1:02:20,  2.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(cell_gene\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,cell_gene\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m----> 3\u001b[0m         results_matrix[i][j]\u001b[38;5;241m=\u001b[39m\u001b[43mmy_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/deepmaps_env/lib/python3.8/multiprocessing/managers.py:835\u001b[0m, in \u001b[0;36mBaseProxy._callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    832\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tls\u001b[38;5;241m.\u001b[39mconnection\n\u001b[1;32m    834\u001b[0m conn\u001b[38;5;241m.\u001b[39msend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id, methodname, args, kwds))\n\u001b[0;32m--> 835\u001b[0m kind, result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#RETURN\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/deepmaps_env/lib/python3.8/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(buf\u001b[38;5;241m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/.conda/envs/deepmaps_env/lib/python3.8/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/deepmaps_env/lib/python3.8/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(cell_gene.shape[0])):\n",
    "    for j in range(i+1,cell_gene.shape[0]):\n",
    "        results_matrix[i][j]=my_dict[(i,j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64b3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 981/10558 [08:18<1:21:05,  1.97it/s] "
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, wait, ALL_COMPLETED, FIRST_COMPLETED\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def action(i):\n",
    "    for j in range(i+1,cell_gene.shape[0]):\n",
    "        results_matrix[i][j]=my_dict[(i,j)]\n",
    "\n",
    "# 创建一个包含2条线程的线程池\n",
    "jobs=[]\n",
    "pool = ThreadPoolExecutor(max_workers=1000)\n",
    "\n",
    "for i in tqdm(range(cell_gene.shape[0])):\n",
    "    jobs.append(pool.submit(action, i))\n",
    "\n",
    "wait(jobs, return_when=ALL_COMPLETED)\n",
    "print(\"main\")\n",
    "\n",
    "pool.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1417cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d30c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d31c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675b5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00354b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b4726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd923952",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sim1_ls,\"./outputs/sim1_ls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8cb735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fac69f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 102 ms, sys: 29.1 ms, total: 131 ms\n",
      "Wall time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, dim, emb_dim=128):\n",
    "        super(AE, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.fc1 = nn.Linear(dim, 512)\n",
    "        self.fc2 = nn.Linear(512, emb_dim)\n",
    "        self.fc3 = nn.Linear(emb_dim, 512)\n",
    "        self.fc4 = nn.Linear(512, dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return F.relu(self.fc2(h1))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.relu(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x.view(-1, self.dim))\n",
    "        return self.decode(z), z\n",
    "    \n",
    "    \n",
    "feature=torch.tensor(gene_cell.T)\n",
    "feature=feature.to(device)\n",
    "model = AE(dim=feature.shape[1]).to(device)\n",
    "ba=feature.shape[0]\n",
    "loader = Data.DataLoader(feature, ba)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "EPOCH_AE = 2000\n",
    "for epoch in range(EPOCH_AE):\n",
    "    embeddings = []\n",
    "    # loss_ls=[]\n",
    "    for _, batch_x in enumerate(loader)\t:\n",
    "        decoded, encoded = model(batch_x)\n",
    "        break\n",
    "        loss1 = loss_func(batch_x, decoded)\n",
    "        loss2 = 0\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            for j in range(i+1,batch_x.shape[0]):\n",
    "                v1=batch_x[i]\n",
    "                v2=batch_x[j]\n",
    "                h1=encoded[i]\n",
    "                h2=encoded[j]\n",
    "                sim1=get_simi(np.array(v1.cpu()),np.array(v2.cpu()))\n",
    "                sim2=loss_exp(h1,h2)\n",
    "                loss2+=sim1*(sim2-sim1).abs()\n",
    "        print(loss1,loss2)\n",
    "        loss=loss1+loss2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        embeddings.append(encoded)\n",
    "    #     loss_ls.append(loss.item())\n",
    "    # scheduler.step(np.mean(loss_ls))\n",
    "#     print('Epoch :', epoch, '|', 'train_loss:%.12f' % loss.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d09154d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10558, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be804cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f7c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa6afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734076d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169a7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64111f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994b3129",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:52\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mget_simi\u001b[0;34m(u1, u2)\u001b[0m\n\u001b[1;32m      4\u001b[0m nz_u2 \u001b[38;5;241m=\u001b[39m u2\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m nz_inter \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(nz_u1) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(nz_u2)))\n\u001b[0;32m----> 6\u001b[0m nz_union \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnz_u1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnz_u2\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(nz_inter) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m     simi_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mlen\u001b[39m(nz_union) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(u1))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, dim, emb_dim=128):\n",
    "        super(AE, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.fc1 = nn.Linear(dim, 512)\n",
    "        self.fc2 = nn.Linear(512, emb_dim)\n",
    "        self.fc3 = nn.Linear(emb_dim, 512)\n",
    "        self.fc4 = nn.Linear(512, dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return F.relu(self.fc2(h1))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.relu(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x.view(-1, self.dim))\n",
    "        return self.decode(z), z\n",
    "    \n",
    "    \n",
    "feature=torch.tensor(gene_cell.T)\n",
    "feature=feature.to(device)\n",
    "model = AE(dim=feature.shape[1]).to(device)\n",
    "ba=5000\n",
    "loader = Data.DataLoader(feature, ba)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "EPOCH_AE = 2000\n",
    "for epoch in range(EPOCH_AE):\n",
    "    embeddings = []\n",
    "    # loss_ls=[]\n",
    "    for _, batch_x in enumerate(loader)\t:\n",
    "        decoded, encoded = model(batch_x)\n",
    "        loss1 = loss_func(batch_x, decoded)\n",
    "        loss2 = 0\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            for j in range(i+1,batch_x.shape[0]):\n",
    "                v1=batch_x[i]\n",
    "                v2=batch_x[j]\n",
    "                h1=encoded[i]\n",
    "                h2=encoded[j]\n",
    "                sim1=get_simi(np.array(v1.cpu()),np.array(v2.cpu()))\n",
    "                sim2=loss_exp(h1,h2)\n",
    "                loss2+=sim1*(sim2-sim1).abs()\n",
    "        print(loss1,loss2)\n",
    "        loss=loss1+loss2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        embeddings.append(encoded)\n",
    "    #     loss_ls.append(loss.item())\n",
    "    # scheduler.step(np.mean(loss_ls))\n",
    "    print('Epoch :', epoch, '|', 'train_loss:%.12f' % loss.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350f2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e592ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4a9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96096e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39be95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea07774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a42b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8775a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9903b09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c251785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DeepMAPS)",
   "language": "python",
   "name": "deepmaps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
