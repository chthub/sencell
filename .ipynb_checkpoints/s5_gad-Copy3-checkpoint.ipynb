{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4c004dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 数量： 21\n",
      "celltype names: ['Macrophages', 'T cell lineage', 'Unknown', 'B cell lineage', 'Innate lymphoid cell NK', 'AT2', 'Monocytes', 'Multiciliated lineage', 'Dendritic cells', 'EC capillary', 'Mast cells', 'Fibroblasts', 'Secretory', 'EC venous', 'Lymphatic EC mature', 'AT1', 'Basal', 'EC arterial', 'Myofibroblasts', 'None', 'Submucosal Secretory']\n",
      "-----------------------  ----\n",
      "Macrophages              6941\n",
      "T cell lineage            749\n",
      "Unknown                   618\n",
      "B cell lineage            374\n",
      "Innate lymphoid cell NK   327\n",
      "AT2                       294\n",
      "Monocytes                 228\n",
      "Multiciliated lineage     194\n",
      "Dendritic cells           177\n",
      "EC capillary              138\n",
      "Mast cells                100\n",
      "Fibroblasts                93\n",
      "Secretory                  86\n",
      "EC venous                  74\n",
      "Lymphatic EC mature        68\n",
      "AT1                        27\n",
      "Basal                      26\n",
      "EC arterial                20\n",
      "Myofibroblasts             17\n",
      "None                        6\n",
      "Submucosal Secretory        1\n",
      "-----------------------  ----\n",
      "各marker list所包含的gene数：\n",
      "  Markers1    Markers2    Markers3    Markers4\n",
      "----------  ----------  ----------  ----------\n",
      "       126          78         145          84\n",
      "total marker genes:  380\n",
      "highly_genes num:  2000\n",
      "After highly genes dropped duplicate:  1935\n",
      "Total gene num: 2286\n",
      "cell num: 10558, gene num: 2286\n",
      "device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from community import community_louvain\n",
    "from torch_geometric.utils import k_hop_subgraph,to_networkx,from_networkx\n",
    "import matplotlib\n",
    "\n",
    "import utils\n",
    "import plots\n",
    "from model_AE import reduction_AE\n",
    "from model_GAT import Encoder,SenGAE,train_GAT\n",
    "from model_Sencell import Sencell\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Main program for sencells')\n",
    "\n",
    "parser.add_argument('--output_dir', type=str, default='./outputs', help='')\n",
    "parser.add_argument('--exp_name', type=str, default='', help='')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.exp_name='s5'\n",
    "\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s.%(msecs)03d [%(levelname)s] [%(filename)s:%(lineno)d] %(message)s',\n",
    "                    datefmt='# %Y-%m-%d %H:%M:%S')\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Part 1: load and process data\n",
    "# cell_cluster_arr在画umap的时候用\n",
    "adata,cluster_cell_ls,cell_cluster_arr,celltype_names=utils.load_data()\n",
    "# plots.umapPlot(adata.obsm['X_umap'],clusters=cell_cluster_arr,labels=celltype_names)\n",
    "\n",
    "new_data,markers_index,\\\n",
    "sen_gene_ls,nonsen_gene_ls,gene_names=utils.process_data(adata,cluster_cell_ls,cell_cluster_arr)\n",
    "\n",
    "print(f'cell num: {new_data.shape[0]}, gene num: {new_data.shape[1]}')\n",
    "\n",
    "gene_cell=new_data.X.toarray().T\n",
    "cell_gene=gene_cell.T\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device: ',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863dcb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b279ff83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent process 156409.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10558/10558 [00:00<00:00, 35942.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for all subprocesses done...\n",
      "All subprocesses done.\n",
      "CPU times: user 3.27 s, sys: 1.38 s, total: 4.64 s\n",
      "Wall time: 55min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_simi(i,my_dict):\n",
    "    for j in range(i+1,cell_gene.shape[0]):\n",
    "        u1=cell_gene[i]\n",
    "        u2=cell_gene[j]\n",
    "        # u1,u2必须是numpy.array，not tensor\n",
    "        nz_u1 = u1.nonzero()[0]\n",
    "        nz_u2 = u2.nonzero()[0]\n",
    "        nz_inter = set(nz_u1) & set(nz_u2)\n",
    "        nz_union = set(nz_u1) | set(nz_u2)\n",
    "        if len(nz_inter) == 0:\n",
    "            simi_score = 1 / (len(nz_union) + len(u1))\n",
    "        elif len(nz_inter) == len(nz_union):\n",
    "            simi_score = (len(nz_union) + len(u1) - 1) / (len(nz_union) + len(u1))\n",
    "        else:\n",
    "            simi_score = len(nz_inter) / len(nz_union)\n",
    "        my_dict[(i,j)]=simi_score\n",
    "\n",
    "\n",
    "def eucliDistance(v1,v2):\n",
    "    # 计算欧氏距离\n",
    "    return F.pairwise_distance(v1.view(1,-1),v2.view(1,-1),p=2)\n",
    "\n",
    "def loss_exp(v1,v2):\n",
    "    return torch.exp(-0.1*eucliDistance(v1,v2))\n",
    "\n",
    "\n",
    "sim1_ls=[]\n",
    "cell_gene=gene_cell.T    \n",
    "results_matrix=np.zeros((cell_gene.shape[0],cell_gene.shape[0])) \n",
    "\n",
    "\n",
    "from multiprocessing import Pool,Manager\n",
    "import os, time, random\n",
    "\n",
    "\n",
    "print('Parent process %s.' % os.getpid())\n",
    "p = Pool()\n",
    "manager = Manager()\n",
    "my_dict = manager.dict()\n",
    "for i in tqdm(range(cell_gene.shape[0])):\n",
    "    p.apply_async(get_simi, args=(i,my_dict,))\n",
    "\n",
    "print('Waiting for all subprocesses done...')\n",
    "p.close()\n",
    "p.join()\n",
    "print('All subprocesses done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1454b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(my_dict,\"./my_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b83e19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07983193277310924"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dict[(0,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5199f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.load(\"./my_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2c4c8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03289473684210526"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[(0,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cba9e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj saved ./my_dict.pl\n"
     ]
    }
   ],
   "source": [
    "from utils import save_objs\n",
    "\n",
    "save_objs(my_dict,\"./my_dict.pl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2423fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f5566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17:17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef7407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fbc41c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10558/10558 [31:46<00:00,  5.54it/s] \n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(cell_gene.shape[0])):\n",
    "    for j in range(i+1,cell_gene.shape[0]):\n",
    "        results_matrix[i][j]=my_dict[(i,j)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dda78f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(results_matrix,\"./results_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab2ad69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb0e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eaf249b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_arr=torch.tensor(1*(cell_gene==0)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8cb735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf11a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim1=torch.tensor(results_matrix).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f259ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a288a224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1797,  0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49789f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac69f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1708962321281433 0.7118785437114148\n",
      "Epoch : 0 | train_loss:0.882774775840\n",
      "0.16793963313102722 0.6656433636494935\n",
      "Epoch : 1 | train_loss:0.833582996781\n",
      "0.16152916848659515 0.6165209743689954\n",
      "Epoch : 2 | train_loss:0.778050142856\n",
      "0.15216512978076935 0.562801331543929\n",
      "Epoch : 3 | train_loss:0.714966461325\n",
      "0.14431104063987732 0.5039958455393712\n",
      "Epoch : 4 | train_loss:0.648306886179\n",
      "0.14084160327911377 0.44097283295416656\n",
      "Epoch : 5 | train_loss:0.581814436233\n",
      "0.13875281810760498 0.37817224352909107\n",
      "Epoch : 6 | train_loss:0.516925061637\n",
      "0.134443461894989 0.31930900843718407\n",
      "Epoch : 7 | train_loss:0.453752470332\n",
      "0.12806689739227295 0.26544836164683966\n",
      "Epoch : 8 | train_loss:0.393515259039\n",
      "0.1207534670829773 0.2179095267681499\n",
      "Epoch : 9 | train_loss:0.338662993851\n",
      "0.1148814782500267 0.18014597524503698\n",
      "Epoch : 10 | train_loss:0.295027453495\n",
      "0.11288569122552872 0.15642693121387685\n",
      "Epoch : 11 | train_loss:0.269312622439\n",
      "0.11277997493743896 0.14518054705959774\n",
      "Epoch : 12 | train_loss:0.257960521997\n",
      "0.11163495481014252 0.14173438747567874\n",
      "Epoch : 13 | train_loss:0.253369342286\n",
      "0.10898211598396301 0.14253200465186644\n",
      "Epoch : 14 | train_loss:0.251514120636\n",
      "0.10649260878562927 0.14531078371189818\n",
      "Epoch : 15 | train_loss:0.251803392498\n",
      "0.10555147379636765 0.14873446732448264\n",
      "Epoch : 16 | train_loss:0.254285941121\n",
      "0.1049884483218193 0.15204364168892623\n",
      "Epoch : 17 | train_loss:0.257032090011\n",
      "0.10383433103561401 0.1548733738507986\n",
      "Epoch : 18 | train_loss:0.258707704886\n",
      "0.10298191010951996 0.15711388661612427\n",
      "Epoch : 19 | train_loss:0.260095796726\n",
      "0.10261858999729156 0.15876938255128967\n",
      "Epoch : 20 | train_loss:0.261387972549\n",
      "0.10205970704555511 0.15986642156386063\n",
      "Epoch : 21 | train_loss:0.261926128609\n",
      "0.10136692970991135 0.16042128672597694\n",
      "Epoch : 22 | train_loss:0.261788216436\n",
      "0.1008642166852951 0.16043378771548159\n",
      "Epoch : 23 | train_loss:0.261298004401\n",
      "0.1003791019320488 0.15990043853660849\n",
      "Epoch : 24 | train_loss:0.260279540469\n",
      "0.09976854175329208 0.1588350496966276\n",
      "Epoch : 25 | train_loss:0.258603591450\n",
      "0.09918919950723648 0.1572724211330755\n",
      "Epoch : 26 | train_loss:0.256461620640\n",
      "0.0986873209476471 0.1552531788707374\n",
      "Epoch : 27 | train_loss:0.253940499818\n",
      "0.09821778535842896 0.15281013237390143\n",
      "Epoch : 28 | train_loss:0.251027917732\n",
      "0.0977872759103775 0.14995703057521156\n",
      "Epoch : 29 | train_loss:0.247744306486\n",
      "0.09741129726171494 0.14670106902717497\n",
      "Epoch : 30 | train_loss:0.244112366289\n",
      "0.09707750380039215 0.143060016175509\n",
      "Epoch : 31 | train_loss:0.240137519976\n",
      "0.09678605943918228 0.13908635303949204\n",
      "Epoch : 32 | train_loss:0.235872412479\n",
      "0.09652584046125412 0.1348834641147426\n",
      "Epoch : 33 | train_loss:0.231409304576\n",
      "0.09624256938695908 0.1306101754671667\n",
      "Epoch : 34 | train_loss:0.226852744854\n",
      "0.0958380326628685 0.1263874060529115\n",
      "Epoch : 35 | train_loss:0.222225438716\n",
      "0.09535295516252518 0.1222572444345933\n",
      "Epoch : 36 | train_loss:0.217610199597\n",
      "0.09494296461343765 0.11829066893533781\n",
      "Epoch : 37 | train_loss:0.213233633549\n",
      "0.09466806799173355 0.11459227322942497\n",
      "Epoch : 38 | train_loss:0.209260341221\n",
      "0.09448584914207458 0.11124673635747881\n",
      "Epoch : 39 | train_loss:0.205732585500\n",
      "0.09435401111841202 0.10826926893414687\n",
      "Epoch : 40 | train_loss:0.202623280053\n",
      "0.09425661712884903 0.10558487558909571\n",
      "Epoch : 41 | train_loss:0.199841492718\n",
      "0.09415091574192047 0.1030410664478976\n",
      "Epoch : 42 | train_loss:0.197191982190\n",
      "0.09401470422744751 0.1004569061354059\n",
      "Epoch : 43 | train_loss:0.194471610363\n",
      "0.09382810443639755 0.09772652627871631\n",
      "Epoch : 44 | train_loss:0.191554630715\n",
      "0.093610979616642 0.09491514258105443\n",
      "Epoch : 45 | train_loss:0.188526122198\n",
      "0.09336068481206894 0.09221908430073003\n",
      "Epoch : 46 | train_loss:0.185579769113\n",
      "0.0930987074971199 0.08985190641438683\n",
      "Epoch : 47 | train_loss:0.182950613912\n",
      "0.09285663068294525 0.08791308259392852\n",
      "Epoch : 48 | train_loss:0.180769713277\n",
      "0.09263963252305984 0.08640077495654165\n",
      "Epoch : 49 | train_loss:0.179040407480\n",
      "0.09242416173219681 0.08520585881617097\n",
      "Epoch : 50 | train_loss:0.177630020548\n",
      "0.09219571948051453 0.08414735369734853\n",
      "Epoch : 51 | train_loss:0.176343073178\n",
      "0.0919635221362114 0.08305164572375792\n",
      "Epoch : 52 | train_loss:0.175015167860\n",
      "0.09175241738557816 0.08180018386697478\n",
      "Epoch : 53 | train_loss:0.173552601253\n",
      "0.09153591096401215 0.08035645802512952\n",
      "Epoch : 54 | train_loss:0.171892368989\n",
      "0.09129934757947922 0.078777191364632\n",
      "Epoch : 55 | train_loss:0.170076538944\n",
      "0.09103962779045105 0.0771864598976383\n",
      "Epoch : 56 | train_loss:0.168226087688\n",
      "0.09076342731714249 0.07572242235471217\n",
      "Epoch : 57 | train_loss:0.166485849672\n",
      "0.09048812091350555 0.07446398296999548\n",
      "Epoch : 58 | train_loss:0.164952103884\n",
      "0.09019169956445694 0.07335884055881593\n",
      "Epoch : 59 | train_loss:0.163550540123\n",
      "0.08976322412490845 0.07227075778013994\n",
      "Epoch : 60 | train_loss:0.162033981905\n",
      "0.0893312618136406 0.07113836751568323\n",
      "Epoch : 61 | train_loss:0.160469629329\n",
      "0.08894187211990356 0.06996222665739386\n",
      "Epoch : 62 | train_loss:0.158904098777\n",
      "0.088596411049366 0.06876715951587357\n",
      "Epoch : 63 | train_loss:0.157363570565\n",
      "0.08832843601703644 0.06757894472452051\n",
      "Epoch : 64 | train_loss:0.155907380742\n",
      "0.08811347186565399 0.06642184151696538\n",
      "Epoch : 65 | train_loss:0.154535313383\n",
      "0.08788323402404785 0.06530743583060847\n",
      "Epoch : 66 | train_loss:0.153190669855\n",
      "0.08762137591838837 0.06422430483801447\n",
      "Epoch : 67 | train_loss:0.151845680756\n",
      "0.08732414245605469 0.06316076577140192\n",
      "Epoch : 68 | train_loss:0.150484908227\n",
      "0.08703194558620453 0.062124962778742326\n",
      "Epoch : 69 | train_loss:0.149156908365\n",
      "0.08675043284893036 0.06113822491017143\n",
      "Epoch : 70 | train_loss:0.147888657759\n",
      "0.08650267124176025 0.0602061864880009\n",
      "Epoch : 71 | train_loss:0.146708857730\n",
      "0.08626335859298706 0.05932613173599889\n",
      "Epoch : 72 | train_loss:0.145589490329\n",
      "0.08601359277963638 0.05849449610755367\n",
      "Epoch : 73 | train_loss:0.144508088887\n",
      "0.08575981855392456 0.057714017786036985\n",
      "Epoch : 74 | train_loss:0.143473836340\n",
      "0.08550672978162766 0.05698778728085539\n",
      "Epoch : 75 | train_loss:0.142494517062\n",
      "0.08525057137012482 0.05630390579586291\n",
      "Epoch : 76 | train_loss:0.141554477166\n",
      "0.08502411097288132 0.05564420380855952\n",
      "Epoch : 77 | train_loss:0.140668314781\n",
      "0.08481582254171371 0.054992725837499895\n",
      "Epoch : 78 | train_loss:0.139808548379\n",
      "0.08460840582847595 0.054346705747409345\n",
      "Epoch : 79 | train_loss:0.138955111576\n",
      "0.08439695090055466 0.0537068560776721\n",
      "Epoch : 80 | train_loss:0.138103806978\n",
      "0.08418092131614685 0.05307381078176552\n",
      "Epoch : 81 | train_loss:0.137254732098\n",
      "0.08397191017866135 0.05244194813777399\n",
      "Epoch : 82 | train_loss:0.136413858316\n",
      "0.08376973122358322 0.05180746903974599\n",
      "Epoch : 83 | train_loss:0.135577200263\n",
      "0.08358534425497055 0.05116982234114523\n",
      "Epoch : 84 | train_loss:0.134755166596\n",
      "0.08339960128068924 0.05052735993897896\n",
      "Epoch : 85 | train_loss:0.133926961220\n",
      "0.08321071416139603 0.0498813689381963\n",
      "Epoch : 86 | train_loss:0.133092083100\n",
      "0.08301853388547897 0.04923617075257756\n",
      "Epoch : 87 | train_loss:0.132254704638\n",
      "0.0828377828001976 0.04859827128970953\n",
      "Epoch : 88 | train_loss:0.131436054090\n",
      "0.08263719081878662 0.04797094377885418\n",
      "Epoch : 89 | train_loss:0.130608134598\n",
      "0.08244552463293076 0.047357519552463326\n",
      "Epoch : 90 | train_loss:0.129803044185\n",
      "0.08226224035024643 0.04675897722540731\n",
      "Epoch : 91 | train_loss:0.129021217576\n",
      "0.08205599337816238 0.04617493968069291\n",
      "Epoch : 92 | train_loss:0.128230933059\n",
      "0.08188824355602264 0.04560407717821132\n",
      "Epoch : 93 | train_loss:0.127492320734\n",
      "0.08171181380748749 0.04504683510096342\n",
      "Epoch : 94 | train_loss:0.126758648908\n",
      "0.08153511583805084 0.044507831682561866\n",
      "Epoch : 95 | train_loss:0.126042947521\n",
      "0.08136384189128876 0.043988225026002185\n",
      "Epoch : 96 | train_loss:0.125352066917\n",
      "0.08119584619998932 0.04348806770981191\n",
      "Epoch : 97 | train_loss:0.124683913910\n",
      "0.08102786540985107 0.04300696947928245\n",
      "Epoch : 98 | train_loss:0.124034834889\n",
      "0.08061190694570541 0.04254217760647279\n",
      "Epoch : 99 | train_loss:0.123154084552\n",
      "0.07937916368246078 0.04209061902200581\n",
      "Epoch : 100 | train_loss:0.121469782704\n",
      "0.07816191017627716 0.0416551838422211\n",
      "Epoch : 101 | train_loss:0.119817094018\n",
      "0.07746055722236633 0.041234038771052396\n",
      "Epoch : 102 | train_loss:0.118694595993\n",
      "0.07746001332998276 0.0408187159192595\n",
      "Epoch : 103 | train_loss:0.118278729249\n",
      "0.07772224396467209 0.0404064711623988\n",
      "Epoch : 104 | train_loss:0.118128715127\n",
      "0.07772033661603928 0.040002707531938304\n",
      "Epoch : 105 | train_loss:0.117723044148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07736320793628693 0.039615282272960795\n",
      "Epoch : 106 | train_loss:0.116978490209\n",
      "0.07688687741756439 0.03924686288109235\n",
      "Epoch : 107 | train_loss:0.116133740299\n",
      "0.07651743292808533 0.03889311460374947\n",
      "Epoch : 108 | train_loss:0.115410547532\n",
      "0.07629422098398209 0.03854412771926128\n",
      "Epoch : 109 | train_loss:0.114838348703\n",
      "0.07620344310998917 0.03818856487811884\n",
      "Epoch : 110 | train_loss:0.114392007988\n",
      "0.07614196836948395 0.03782662188251436\n",
      "Epoch : 111 | train_loss:0.113968590252\n",
      "0.0760202631354332 0.037467106710646826\n",
      "Epoch : 112 | train_loss:0.113487369846\n",
      "0.07583703845739365 0.03711723574441723\n",
      "Epoch : 113 | train_loss:0.112954274202\n",
      "0.07560402899980545 0.03678309770097983\n",
      "Epoch : 114 | train_loss:0.112387126701\n",
      "0.07539516687393188 0.03646492724205141\n",
      "Epoch : 115 | train_loss:0.111860094116\n",
      "0.07521449774503708 0.03615604650510518\n",
      "Epoch : 116 | train_loss:0.111370544250\n",
      "0.07508029043674469 0.035849357490869295\n",
      "Epoch : 117 | train_loss:0.110929647928\n",
      "0.07496192306280136 0.035539308895762026\n",
      "Epoch : 118 | train_loss:0.110501231959\n",
      "0.07483971118927002 0.035229711573755665\n",
      "Epoch : 119 | train_loss:0.110069422763\n",
      "0.07469898462295532 0.0349267906051734\n",
      "Epoch : 120 | train_loss:0.109625775228\n",
      "0.07454299181699753 0.03463606446311888\n",
      "Epoch : 121 | train_loss:0.109179056280\n",
      "0.0743948295712471 0.0343566565380217\n",
      "Epoch : 122 | train_loss:0.108751486109\n",
      "0.07425548136234283 0.03408307591661554\n",
      "Epoch : 123 | train_loss:0.108338557279\n",
      "0.07413316518068314 0.03381226139930699\n",
      "Epoch : 124 | train_loss:0.107945426580\n",
      "0.07400970160961151 0.03354341472488242\n",
      "Epoch : 125 | train_loss:0.107553116334\n",
      "0.07387557625770569 0.033277190682147004\n",
      "Epoch : 126 | train_loss:0.107152766940\n",
      "0.07373329997062683 0.03301692456785108\n",
      "Epoch : 127 | train_loss:0.106750224538\n",
      "0.0735848918557167 0.0327636417509286\n",
      "Epoch : 128 | train_loss:0.106348533607\n",
      "0.07344163954257965 0.03251753931970634\n",
      "Epoch : 129 | train_loss:0.105959178862\n",
      "0.07330844551324844 0.03227470908294286\n",
      "Epoch : 130 | train_loss:0.105583154596\n",
      "0.07318542897701263 0.03203575368034019\n",
      "Epoch : 131 | train_loss:0.105221182657\n",
      "0.07309255748987198 0.03179872494904782\n",
      "Epoch : 132 | train_loss:0.104891282439\n",
      "0.07304543256759644 0.03156865131876086\n",
      "Epoch : 133 | train_loss:0.104614083886\n",
      "0.07293900102376938 0.031341217131699656\n",
      "Epoch : 134 | train_loss:0.104280218155\n",
      "0.07271985709667206 0.031117427103386906\n",
      "Epoch : 135 | train_loss:0.103837284200\n",
      "0.07257112115621567 0.030897797863011854\n",
      "Epoch : 136 | train_loss:0.103468919019\n",
      "0.07250767201185226 0.030682901223442333\n",
      "Epoch : 137 | train_loss:0.103190573235\n",
      "0.0723741203546524 0.030469289042962942\n",
      "Epoch : 138 | train_loss:0.102843409398\n",
      "0.07221752405166626 0.030261087942716813\n",
      "Epoch : 139 | train_loss:0.102478611994\n",
      "0.07212018221616745 0.03005883190054264\n",
      "Epoch : 140 | train_loss:0.102179014117\n",
      "0.07198178768157959 0.029859254419163334\n",
      "Epoch : 141 | train_loss:0.101841042101\n",
      "0.07182662934064865 0.02966254489077843\n",
      "Epoch : 142 | train_loss:0.101489174231\n",
      "0.07171062380075455 0.029469913943160564\n",
      "Epoch : 143 | train_loss:0.101180537744\n",
      "0.07159017771482468 0.029281384587541617\n",
      "Epoch : 144 | train_loss:0.100871562302\n",
      "0.07145212590694427 0.029097095909579755\n",
      "Epoch : 145 | train_loss:0.100549221817\n",
      "0.07133182883262634 0.028917121316488877\n",
      "Epoch : 146 | train_loss:0.100248950149\n",
      "0.07120802998542786 0.028738600211550794\n",
      "Epoch : 147 | train_loss:0.099946630197\n",
      "0.07108575850725174 0.02856417238269385\n",
      "Epoch : 148 | train_loss:0.099649930890\n",
      "0.07096704095602036 0.028393451744965485\n",
      "Epoch : 149 | train_loss:0.099360492701\n",
      "0.07084131985902786 0.028223367052004306\n",
      "Epoch : 150 | train_loss:0.099064686911\n",
      "0.07071024179458618 0.02805907791697984\n",
      "Epoch : 151 | train_loss:0.098769319712\n",
      "0.07056757807731628 0.02789659797187627\n",
      "Epoch : 152 | train_loss:0.098464176049\n",
      "0.07040933519601822 0.02773821316359634\n",
      "Epoch : 153 | train_loss:0.098147548360\n",
      "0.07031476497650146 0.027581890881282857\n",
      "Epoch : 154 | train_loss:0.097896655858\n",
      "0.07018259912729263 0.027428617533910186\n",
      "Epoch : 155 | train_loss:0.097611216661\n",
      "0.0700429379940033 0.02727842587947202\n",
      "Epoch : 156 | train_loss:0.097321363873\n",
      "0.06992769986391068 0.027133066774264705\n",
      "Epoch : 157 | train_loss:0.097060766638\n",
      "0.06983227282762527 0.026985812948237688\n",
      "Epoch : 158 | train_loss:0.096818085776\n",
      "0.06974901258945465 0.02684755144719447\n",
      "Epoch : 159 | train_loss:0.096596564037\n",
      "0.06965075433254242 0.02670378598211636\n",
      "Epoch : 160 | train_loss:0.096354540315\n",
      "0.069521464407444 0.026571861559109858\n",
      "Epoch : 161 | train_loss:0.096093325967\n",
      "0.06936422735452652 0.02643168344139787\n",
      "Epoch : 162 | train_loss:0.095795910796\n",
      "0.0692305713891983 0.02630170577289379\n",
      "Epoch : 163 | train_loss:0.095532277162\n",
      "0.06913983076810837 0.026173448288148035\n",
      "Epoch : 164 | train_loss:0.095313279056\n",
      "0.06902988255023956 0.026042726918474455\n",
      "Epoch : 165 | train_loss:0.095072609469\n",
      "0.06889083981513977 0.025923678583254662\n",
      "Epoch : 166 | train_loss:0.094814518398\n",
      "0.06878624856472015 0.025794712048953578\n",
      "Epoch : 167 | train_loss:0.094580960614\n",
      "0.06868845224380493 0.025675887133935607\n",
      "Epoch : 168 | train_loss:0.094364339378\n",
      "0.06857558339834213 0.0255588716036088\n",
      "Epoch : 169 | train_loss:0.094134455002\n",
      "0.06846681982278824 0.025438990228545504\n",
      "Epoch : 170 | train_loss:0.093905810051\n",
      "0.06835171580314636 0.025326982277292555\n",
      "Epoch : 171 | train_loss:0.093678698080\n",
      "0.06823493540287018 0.025212990780546757\n",
      "Epoch : 172 | train_loss:0.093447926183\n",
      "0.06812981516122818 0.025100866128235786\n",
      "Epoch : 173 | train_loss:0.093230681289\n",
      "0.06803986430168152 0.02499478255056381\n",
      "Epoch : 174 | train_loss:0.093034646852\n",
      "0.06793076545000076 0.02488523307413523\n",
      "Epoch : 175 | train_loss:0.092815998524\n",
      "0.06781377643346786 0.02478039773262834\n",
      "Epoch : 176 | train_loss:0.092594174166\n",
      "0.06771385669708252 0.024679255020586134\n",
      "Epoch : 177 | train_loss:0.092393111718\n",
      "0.06761191040277481 0.02457476744020101\n",
      "Epoch : 178 | train_loss:0.092186677843\n",
      "0.06749088317155838 0.02447977022856904\n",
      "Epoch : 179 | train_loss:0.091970653400\n",
      "0.06739281862974167 0.024377065432592625\n",
      "Epoch : 180 | train_loss:0.091769884062\n",
      "0.06728637963533401 0.02428147490010751\n",
      "Epoch : 181 | train_loss:0.091567854535\n",
      "0.0671829879283905 0.024187245259662198\n",
      "Epoch : 182 | train_loss:0.091370233188\n",
      "0.06708819419145584 0.02409208502627306\n",
      "Epoch : 183 | train_loss:0.091180279218\n",
      "0.06698591262102127 0.024000733434596494\n",
      "Epoch : 184 | train_loss:0.090986646056\n",
      "0.06688036769628525 0.023909447296916877\n",
      "Epoch : 185 | train_loss:0.090789814993\n",
      "0.06677370518445969 0.02382088211641327\n",
      "Epoch : 186 | train_loss:0.090594587301\n",
      "0.06667625159025192 0.023733268183683317\n",
      "Epoch : 187 | train_loss:0.090409519774\n",
      "0.06670314818620682 0.0236488707722877\n",
      "Epoch : 188 | train_loss:0.090352018958\n",
      "0.06671088933944702 0.02356155345578337\n",
      "Epoch : 189 | train_loss:0.090272442795\n",
      "0.06664907187223434 0.023490021514107808\n",
      "Epoch : 190 | train_loss:0.090139093386\n",
      "0.06631916761398315 0.023398357370826052\n",
      "Epoch : 191 | train_loss:0.089717524985\n",
      "0.06610623747110367 0.023327151288914195\n",
      "Epoch : 192 | train_loss:0.089433388760\n",
      "0.0661436915397644 0.023237307942616872\n",
      "Epoch : 193 | train_loss:0.089380999482\n",
      "0.06602443009614944 0.023159878266039154\n",
      "Epoch : 194 | train_loss:0.089184308362\n",
      "0.06571260839700699 0.023084716178691993\n",
      "Epoch : 195 | train_loss:0.088797324576\n",
      "0.06562212854623795 0.023008883550444725\n",
      "Epoch : 196 | train_loss:0.088631012097\n",
      "0.06559782475233078 0.022933675540641435\n",
      "Epoch : 197 | train_loss:0.088531500293\n",
      "0.06540179252624512 0.022860301274321877\n",
      "Epoch : 198 | train_loss:0.088262093801\n",
      "0.06527993828058243 0.02279409986502622\n",
      "Epoch : 199 | train_loss:0.088074038146\n",
      "0.06522845476865768 0.022716557387734253\n",
      "Epoch : 200 | train_loss:0.087945012156\n",
      "0.06510297954082489 0.02265058619861065\n",
      "Epoch : 201 | train_loss:0.087753565739\n",
      "0.06497985869646072 0.022578559430704317\n",
      "Epoch : 202 | train_loss:0.087558418127\n",
      "0.0648934468626976 0.02250987490196209\n",
      "Epoch : 203 | train_loss:0.087403321765\n",
      "0.06480931490659714 0.022442539603719877\n",
      "Epoch : 204 | train_loss:0.087251854510\n",
      "0.06468819081783295 0.022380025798243844\n",
      "Epoch : 205 | train_loss:0.087068216616\n",
      "0.06459049880504608 0.022309558584443712\n",
      "Epoch : 206 | train_loss:0.086900057389\n",
      "0.06450758129358292 0.022248013605544147\n",
      "Epoch : 207 | train_loss:0.086755594899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06441622227430344 0.02218196764963922\n",
      "Epoch : 208 | train_loss:0.086598189924\n",
      "0.06430891156196594 0.022118827961322536\n",
      "Epoch : 209 | train_loss:0.086427739523\n",
      "0.06421475112438202 0.02205673146922105\n",
      "Epoch : 210 | train_loss:0.086271482594\n",
      "0.06412819027900696 0.021996517376459246\n",
      "Epoch : 211 | train_loss:0.086124707655\n",
      "0.0640370100736618 0.021933661954285262\n",
      "Epoch : 212 | train_loss:0.085970672028\n",
      "0.06393861025571823 0.021881214305419984\n",
      "Epoch : 213 | train_loss:0.085819824561\n",
      "0.06386168301105499 0.021815057111945372\n",
      "Epoch : 214 | train_loss:0.085676740123\n",
      "0.06377695500850677 0.02176256948515139\n",
      "Epoch : 215 | train_loss:0.085539524494\n",
      "0.06372802704572678 0.02169919351831129\n",
      "Epoch : 216 | train_loss:0.085427220564\n",
      "0.06368138641119003 0.021660830466178446\n",
      "Epoch : 217 | train_loss:0.085342216877\n",
      "0.06367575377225876 0.021608980946291698\n",
      "Epoch : 218 | train_loss:0.085284734719\n",
      "0.06363469362258911 0.02162384504555651\n",
      "Epoch : 219 | train_loss:0.085258538668\n",
      "0.063595250248909 0.021541385351563136\n",
      "Epoch : 220 | train_loss:0.085136635600\n",
      "0.06340114027261734 0.021500672693662237\n",
      "Epoch : 221 | train_loss:0.084901812966\n",
      "0.06324336677789688 0.02138052543725772\n",
      "Epoch : 222 | train_loss:0.084623892215\n",
      "0.06315182894468307 0.02132498665556783\n",
      "Epoch : 223 | train_loss:0.084476815600\n",
      "0.06312799453735352 0.021283561794469268\n",
      "Epoch : 224 | train_loss:0.084411556332\n",
      "0.06305326521396637 0.02122792723278092\n",
      "Epoch : 225 | train_loss:0.084281192447\n",
      "0.0628632977604866 0.021198764364033895\n",
      "Epoch : 226 | train_loss:0.084062062125\n",
      "0.0627688467502594 0.021124034260710974\n",
      "Epoch : 227 | train_loss:0.083892881011\n",
      "0.06272909790277481 0.02107694233748112\n",
      "Epoch : 228 | train_loss:0.083806040240\n",
      "0.06267326325178146 0.02103253685937792\n",
      "Epoch : 229 | train_loss:0.083705800111\n",
      "0.06255149096250534 0.020979698014548125\n",
      "Epoch : 230 | train_loss:0.083531188977\n",
      "0.062419310212135315 0.020936885832884226\n",
      "Epoch : 231 | train_loss:0.083356196045\n",
      "0.06235485151410103 0.020889538416088527\n",
      "Epoch : 232 | train_loss:0.083244389930\n",
      "0.062299828976392746 0.020842804447366595\n",
      "Epoch : 233 | train_loss:0.083142633424\n",
      "0.06219841167330742 0.020797834501919996\n",
      "Epoch : 234 | train_loss:0.082996246175\n",
      "0.06208721548318863 0.020758423489453524\n",
      "Epoch : 235 | train_loss:0.082845638973\n",
      "0.0620226114988327 0.020708621818254162\n",
      "Epoch : 236 | train_loss:0.082731233317\n",
      "0.061942171305418015 0.020668182367117417\n",
      "Epoch : 237 | train_loss:0.082610353673\n",
      "0.061836786568164825 0.02062272658859422\n",
      "Epoch : 238 | train_loss:0.082459513157\n",
      "0.061745621263980865 0.020581204070081002\n",
      "Epoch : 239 | train_loss:0.082326825334\n",
      "0.061686329543590546 0.020536852467481846\n",
      "Epoch : 240 | train_loss:0.082223182011\n",
      "0.06160355731844902 0.020498898831359493\n",
      "Epoch : 241 | train_loss:0.082102456150\n",
      "0.06150513514876366 0.020453724033284784\n",
      "Epoch : 242 | train_loss:0.081958859182\n",
      "0.061417773365974426 0.02041264303513237\n",
      "Epoch : 243 | train_loss:0.081830416401\n",
      "0.06135653331875801 0.020375225266504017\n",
      "Epoch : 244 | train_loss:0.081731758585\n",
      "0.06129143759608269 0.02033170435228679\n",
      "Epoch : 245 | train_loss:0.081623141948\n",
      "0.061213962733745575 0.020292086533974976\n",
      "Epoch : 246 | train_loss:0.081506049268\n",
      "0.061158280819654465 0.02025746553125535\n",
      "Epoch : 247 | train_loss:0.081415746351\n",
      "0.06115144118666649 0.020213334539086393\n",
      "Epoch : 248 | train_loss:0.081364775726\n",
      "0.06116243079304695 0.020188489421163764\n",
      "Epoch : 249 | train_loss:0.081350920214\n",
      "0.06118104234337807 0.020140707456136324\n",
      "Epoch : 250 | train_loss:0.081321749800\n",
      "0.06111866608262062 0.020134108491296033\n",
      "Epoch : 251 | train_loss:0.081252774574\n",
      "0.06095987185835838 0.02008711967464648\n",
      "Epoch : 252 | train_loss:0.081046991533\n",
      "0.06072111055254936 0.02009896099137693\n",
      "Epoch : 253 | train_loss:0.080820071544\n",
      "0.060657862573862076 0.020016310269047006\n",
      "Epoch : 254 | train_loss:0.080674172843\n",
      "0.06065885350108147 0.01998787423535715\n",
      "Epoch : 255 | train_loss:0.080646727736\n",
      "0.06067569926381111 0.019920202974365833\n",
      "Epoch : 256 | train_loss:0.080595902238\n",
      "0.060525424778461456 0.019895291992750565\n",
      "Epoch : 257 | train_loss:0.080420716771\n",
      "0.060346487909555435 0.019848363326239064\n",
      "Epoch : 258 | train_loss:0.080194851236\n",
      "0.060265202075242996 0.01983520726308091\n",
      "Epoch : 259 | train_loss:0.080100409338\n",
      "0.06027233228087425 0.019781235096300892\n",
      "Epoch : 260 | train_loss:0.080053567377\n",
      "0.060140009969472885 0.019753371318063026\n",
      "Epoch : 261 | train_loss:0.079893381288\n",
      "0.05998186022043228 0.019709895987869295\n",
      "Epoch : 262 | train_loss:0.079691756208\n",
      "0.05993184447288513 0.01967577236592042\n",
      "Epoch : 263 | train_loss:0.079607616839\n",
      "0.05992135778069496 0.01965839825503514\n",
      "Epoch : 264 | train_loss:0.079579756036\n",
      "0.05983864888548851 0.019615603822724148\n",
      "Epoch : 265 | train_loss:0.079454252708\n",
      "0.059686895459890366 0.01960258068175707\n",
      "Epoch : 266 | train_loss:0.079289476142\n",
      "0.059649933129549026 0.019552198758873363\n",
      "Epoch : 267 | train_loss:0.079202131888\n",
      "0.059615958482027054 0.019537397831002248\n",
      "Epoch : 268 | train_loss:0.079153356313\n",
      "0.059542831033468246 0.01948868289174516\n",
      "Epoch : 269 | train_loss:0.079031513925\n",
      "0.059412214905023575 0.019478081584883525\n",
      "Epoch : 270 | train_loss:0.078890296490\n",
      "0.05937214940786362 0.019431600799488077\n",
      "Epoch : 271 | train_loss:0.078803750207\n",
      "0.059312961995601654 0.019431007958917026\n",
      "Epoch : 272 | train_loss:0.078743969955\n",
      "0.059251125901937485 0.01937881886786159\n",
      "Epoch : 273 | train_loss:0.078629944770\n",
      "0.059128254652023315 0.019378424270909952\n",
      "Epoch : 274 | train_loss:0.078506678923\n",
      "0.05910380184650421 0.019319553811832205\n",
      "Epoch : 275 | train_loss:0.078423355658\n",
      "0.05903637781739235 0.019315499069941525\n",
      "Epoch : 276 | train_loss:0.078351876887\n",
      "0.05897014960646629 0.019259628179693587\n",
      "Epoch : 277 | train_loss:0.078229777786\n",
      "0.05885082483291626 0.019257308088313482\n",
      "Epoch : 278 | train_loss:0.078108132921\n",
      "0.05881359428167343 0.01920285716192699\n",
      "Epoch : 279 | train_loss:0.078016451444\n",
      "0.05873293802142143 0.019198714871309985\n",
      "Epoch : 280 | train_loss:0.077931652893\n",
      "0.058680251240730286 0.01914218739330109\n",
      "Epoch : 281 | train_loss:0.077822438634\n",
      "0.058583732694387436 0.01913098735741403\n",
      "Epoch : 282 | train_loss:0.077714720052\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, dim, emb_dim=128):\n",
    "        super(AE, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.fc1 = nn.Linear(dim, 512)\n",
    "        self.fc2 = nn.Linear(512, emb_dim)\n",
    "        self.fc3 = nn.Linear(emb_dim, 512)\n",
    "        self.fc4 = nn.Linear(512, dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return F.relu(self.fc2(h1))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.relu(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x.view(-1, self.dim))\n",
    "        return self.decode(z), z\n",
    "    \n",
    "    \n",
    "feature=torch.tensor(gene_cell.T)\n",
    "feature=feature.to(device)\n",
    "model = AE(dim=feature.shape[1]).to(device)\n",
    "ba=feature.shape[0]\n",
    "loader = Data.DataLoader(feature, ba)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def loss_expmatrix(encoded):\n",
    "    return torch.exp(-0.1*torch.cdist(encoded,encoded))\n",
    "\n",
    "\n",
    "def get_loss1(batch_x, decoded,bool_arr):\n",
    "    return torch.abs((batch_x-decoded)*bool_arr).sum()\n",
    "\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "EPOCH_AE = 2000\n",
    "for epoch in range(EPOCH_AE):\n",
    "    embeddings = []\n",
    "    # loss_ls=[]\n",
    "    for _, batch_x in enumerate(loader):\n",
    "        decoded, encoded = model(batch_x)\n",
    "#         if epoch %2  ==0:\n",
    "#             loss1 = get_loss1(batch_x, decoded,bool_arr)\n",
    "#         else:\n",
    "        loss1=loss_func(batch_x,decoded)\n",
    "        sim2=loss_expmatrix(encoded)\n",
    "        loss2=10*(sim1*(torch.triu(sim2-sim1).abs())).mean()\n",
    "        print(loss1.item(),loss2.item())\n",
    "        loss=loss1+loss2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        embeddings.append(encoded)\n",
    "    #     loss_ls.append(loss.item())\n",
    "    # scheduler.step(np.mean(loss_ls))\n",
    "    print('Epoch :', epoch, '|', 'train_loss:%.12f' % loss.data)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103905c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_embed=torch.cat(embeddings)\n",
    "cell_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3cf3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def umapPlot(embedding,clusters=None,reduce=False,labels=None):\n",
    "    # if tensor: embedding should be .cpu().detach()\n",
    "    # clusters: Nxt\n",
    "    # t里面存的是行的index\n",
    "    if reduce:\n",
    "        reducer = umap.UMAP()\n",
    "#         embedding = TSNE(n_components=2, learning_rate='auto',\n",
    "#                   init='random', perplexity=3).fit_transform(embedding)\n",
    "        embedding = reducer.fit_transform(embedding)\n",
    "    \n",
    "    plt.figure(figsize=(6,6),dpi=300)\n",
    "    if clusters is None:\n",
    "        plt.scatter(embedding[:,0],embedding[:,1],alpha=0.5,s=5)\n",
    "    else:\n",
    "        for cluster,label in zip(clusters,labels):\n",
    "            plt.scatter(embedding[cluster,0],embedding[cluster,1],alpha=0.5,s=5,label=label)\n",
    "        plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "         \n",
    "            \n",
    "            \n",
    "umapPlot(cell_embed.cpu().detach().numpy(),reduce=True,\n",
    "         clusters=cluster_cell_ls,labels=celltype_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2f01d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa92960e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9991e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=cell_embed.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5f046757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2833134 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00663263, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.1639814 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.0848366 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d39edb22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U4'), dtype('float32')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mTSNE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperplexity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/deepmaps_env/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:932\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m    output.\u001b[39;00m\n\u001b[1;32m    915\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/.conda/envs/deepmaps_env/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:841\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;66;03m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[1;32m    839\u001b[0m degrees_of_freedom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tsne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdegrees_of_freedom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mX_embedded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_embedded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mneighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneighbors_nn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mskip_num_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_num_points\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/deepmaps_env/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:882\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# Learning schedule (part 1): do 250 iteration with lower momentum but\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# higher learning rate controlled via the early exaggeration parameter\u001b[39;00m\n\u001b[1;32m    881\u001b[0m P \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_exaggeration\n\u001b[0;32m--> 882\u001b[0m params, kl_divergence, it \u001b[38;5;241m=\u001b[39m \u001b[43m_gradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    885\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[t-SNE] KL divergence after \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m iterations with early \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    886\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexaggeration: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (it \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, kl_divergence))\n",
      "File \u001b[0;32m~/.conda/envs/deepmaps_env/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:372\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m np\u001b[38;5;241m.\u001b[39mclip(gains, min_gain, np\u001b[38;5;241m.\u001b[39minf, out\u001b[38;5;241m=\u001b[39mgains)\n\u001b[1;32m    371\u001b[0m grad \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m gains\n\u001b[0;32m--> 372\u001b[0m update \u001b[38;5;241m=\u001b[39m momentum \u001b[38;5;241m*\u001b[39m update \u001b[38;5;241m-\u001b[39m \u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\n\u001b[1;32m    373\u001b[0m p \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m update\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_convergence:\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U4'), dtype('float32')) -> None"
     ]
    }
   ],
   "source": [
    "embedding = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(torch.tensor(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d09154d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be804cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  4],\n",
       "        [ 9, 16]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2],[3,4]])*torch.tensor([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f7c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa6afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734076d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169a7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64111f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994b3129",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:52\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mget_simi\u001b[0;34m(u1, u2)\u001b[0m\n\u001b[1;32m      4\u001b[0m nz_u2 \u001b[38;5;241m=\u001b[39m u2\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m nz_inter \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(nz_u1) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(nz_u2)))\n\u001b[0;32m----> 6\u001b[0m nz_union \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnz_u1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnz_u2\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(nz_inter) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m     simi_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mlen\u001b[39m(nz_union) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(u1))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, dim, emb_dim=128):\n",
    "        super(AE, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.fc1 = nn.Linear(dim, 512)\n",
    "        self.fc2 = nn.Linear(512, emb_dim)\n",
    "        self.fc3 = nn.Linear(emb_dim, 512)\n",
    "        self.fc4 = nn.Linear(512, dim)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return F.relu(self.fc2(h1))\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.relu(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x.view(-1, self.dim))\n",
    "        return self.decode(z), z\n",
    "    \n",
    "    \n",
    "feature=torch.tensor(gene_cell.T)\n",
    "feature=feature.to(device)\n",
    "model = AE(dim=feature.shape[1]).to(device)\n",
    "ba=5000\n",
    "loader = Data.DataLoader(feature, ba)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "EPOCH_AE = 2000\n",
    "for epoch in range(EPOCH_AE):\n",
    "    embeddings = []\n",
    "    # loss_ls=[]\n",
    "    for _, batch_x in enumerate(loader)\t:\n",
    "        decoded, encoded = model(batch_x)\n",
    "        loss1 = loss_func(batch_x, decoded)\n",
    "        loss2 = 0\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            for j in range(i+1,batch_x.shape[0]):\n",
    "                v1=batch_x[i]\n",
    "                v2=batch_x[j]\n",
    "                h1=encoded[i]\n",
    "                h2=encoded[j]\n",
    "                sim1=get_simi(np.array(v1.cpu()),np.array(v2.cpu()))\n",
    "                sim2=loss_exp(h1,h2)\n",
    "                loss2+=sim1*(sim2-sim1).abs()\n",
    "        print(loss1,loss2)\n",
    "        loss=loss1+loss2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        embeddings.append(encoded)\n",
    "    #     loss_ls.append(loss.item())\n",
    "    # scheduler.step(np.mean(loss_ls))\n",
    "    print('Epoch :', epoch, '|', 'train_loss:%.12f' % loss.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350f2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e592ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4a9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96096e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39be95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea07774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a42b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c8775a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9903b09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c251785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DeepMAPS)",
   "language": "python",
   "name": "deepmaps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
